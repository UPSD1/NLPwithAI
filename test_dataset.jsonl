{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I've made a list of every major topic that I can find/remember covering- do you notice anything major missing? I also find topic-lists are helpful for me in getting organized, so if you don't notice any issues, feel free to use it :)\n\n"}, {"role": "assistant", "content": "I\u2019ve pinned this post because I am sure others will find it useful. You do a pretty good job of covering the high level topics. There are smaller details missing so I will follow your format and do the Pre-midterm and Post Midterm as a list below. These are the high level topics that will be covered. I believe I got everything but will have another TA and Prof. Claire double check for me\n\n**Pre-Midterm Topics**:\n\u2013 Language modeling: n-grams, Bayes rule, perplexity, smoothing, Zipf\u2019s law\n\u2013 Extrinsic vs. intrinsic evaluation\n\u2013 Fake vs. real news classification: language modeling\n\u2013 Supervised ML for classification: na\u00efve Bayes, logistic regression\n    \u2013 Sentiment classification\n    \u2013 WSD\n    \u2013 Rhetorical question detection \u2013 Collocational features\n    \u2013 Co-occurrence features\n\u2013 R/P/F, accuracy, train/validation/test sets; cross- validation;\n\u2013 Sequence-tagging\n    \u2013 HMMs, Viterbi\n    \u2013 MEMMs\n    \u2013 P-o-s tagging\n    \u2013 NER\n    \u2013 Chunking\n    \u2013 Semantic role labelling\n    \u2013 Fine-grained opinion extraction\n\u2013 Representing words\n    \u2013 Vector representation, measuring similarity\n    \u2013 Word embeddings (static), word2vec\n\n**Post Midterm Topics**:\n\u2013 Deep learning approaches (neural networks)\n    \u2013 Perceptron, feedforward NNs, training via error backpropagation, cross entropy loss, overfitting\n    \u2013 Recurrent NNs, backpropagation through time, bidirectional RNNs, LSTMs, computation graphs,\n    \u2013 Neural LMs\n    \u2013 Encoder-decoder architecture, attention, contextual word embeddings, transformers\n    \u2013 Text generation applications using RNNs\n\u2013 Bert\n    \u2013 Masked Language Modeling\n    \u2013 Pre-train + fine tune\n\u2013 Question answering\n\u2013 Discourse analysis: coherence, cohesion, NP coreference\n\u2013 Text summarization"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello!\n\nI was wondering if the overall final exam grades or key would be released at some point? I was expecting a bit higher of a grade on student center but maybe I did not do as well as I thought on the final. \n\nThank you!"}, {"role": "assistant", "content": "Hi Benjamin!  Yes, we'll release the exam grades and answer key, etc. AFTER all of the students have taken the make-up final on Jan 20.  (Since the topics of the main exam and make-up are the same, we don't want to release anything before then.)   You got a 94/136 on the final exam, which is a 69/100...so not great.   BUT I gave +18pts for a curve, so you did well --- 94/100.   The low scores for you were the midterm (78/100) and the critiques (2, 1.5, 1.5 = 75/100).  Together the latter make up 20% of the grade.\n\nWe gave you one of the few A+'s for participation ==>  98/100.\n\nSo let's revisit this again after the answer keys to the final exam are posted."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I hope all is well :)\n\nI just wanted to check when the make-up final will be held since I haven't heard back from professor Cardie although I emailed her about a week ago, and from TAs on the ed post that I made before. \n\n"}, {"role": "assistant", "content": "Hi John.  See #1206."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When would I be able to take the makeup? I am ready to take it and am feeling better. "}, {"role": "assistant", "content": "Hi Jack.  See #1206."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Last week, I have made a Ed stem post and get approved for a makeup final which I really appreciated. I also forwarded my SDS letter to Prof. Cardie. I have recovered and feel well now. I am wondering when will the makeup final be? Could I get noticed if it is scheduled? \n\n"}, {"role": "assistant", "content": "We will send an email shortly regarding this to those that haven\u2019t taken the exam. You will have reasonable notice before having to take the exam"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! First of all, thank you to all of the course staff for being so supportive with providing accommodations for my mental health this semester, I don\u2019t think I would have been able to stay in this class, much less do as well as I\u2019ve managed to without the help of Professor Cardie, Magd, Sabhya, and every single TA who I pestered with questions in office hours! I had a pretty rough experience in my last CS class because I was too nervous to ask for accommodations and it seriously affected my performance and my relationship with CS. So, thank you so so much for fostering an environment where I felt like I could ask for help (and also an environment that was generally just a good time). Seriously, you guys made all the difference!! <3\n\nSecond, I wanted to let you know that I am home and will be getting my booster shot soon so I\u2019m not sure how much I\u2019ll be able to prepare to take the exam this upcoming week (depending on how the booster shot affects me). I know Professor Cardie said I could take it when I was ready, but I wasn\u2019t sure of the timescale on that so I just wanted to let you know! Let me know if you have any more info about making up the final :)\n\nI hope you all are staying safe & well, and have a happy holidays!!"}, {"role": "assistant", "content": "Hi Anna!\n\nGlad you are home and safe. We\u2019re happy that you enjoyed the class and that the course staff were able to make your experience even better :).\n\nIn terms of the final, we will notify you when we finalize the date. We\u2019ll provide a reasonable notice but we are currently looking at late January for the final. In the meantime, have a wonderful winter break!\n\nCheers\n4740 Course Staff"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "First, thank you all so much for a great semester. This is only the third CS course I've ever taken, so I was occasionally out of my depth, but I have no regrets and learned a ton!\n\nI'm a third-year PhD student in Romance Studies and one of my main interests is applying state-of-the-art NLP and cognitive science approaches to literary analysis, particularly poetry. Unfortunately, there are very few people in my field doing this, and practically no one (to my knowledge) here in my department. I built a dataset of ~6,000 English-language haiku and proposed an experiment for another seminar using BERT and GPT-3 to investigate techniques for measuring the quality of generated haiku poetry. I'm also working on a few experiments with some cog sci faculty on GPT-3 and poetry as well (with a human experimental component, which is super exciting!). \n\nIf any of the course staff is interested in this kind of thing or has any advice, I would absolutely love to stay in touch or share what I've been working on. I am always open to collaborating, feedback, and I am super passionate about interdisciplinary work.  \n\nThank you all again, and have a great break!"}, {"role": "assistant", "content": "This is very cool!   Are you in touch with our Digital Humanities faculty (in CIS and more broadly)?  The main CSy types are David Mimno and Matt Wilkens.  Both are in the Information Science department.\n\nhttps://cornell.campusgroups.com/dhc/home/\n\nhttps://digitalscholarship.library.cornell.edu/\n\nThe latter link indicates that there was a summer graduate fellowship at least for last summer of 2021."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "@sabhyac26"}, {"role": "assistant", "content": "Thanks for the support \u2764\ufe0f \u2764\ufe0f \n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I'm so sorry I'm a fool I somehow thought we only needed 2 instead of 3 critiques for 4740. Could I submit c6 late now and take a 7 letter grade penalty? Alternatively, since c6 was already discussed, I could critique another paper:\n\nex.\n\n1. Machine-to-corpus-to-machine training regime: https://arxiv.org/pdf/2110.07178.pdf\n\n2. Character-level language model: https://arxiv.org/pdf/1508.06615.pdf\n\n3. Fixing bottleneck of fixed-length hidden in NMT translation: https://arxiv.org/pdf/1409.0473.pdf \n\n"}, {"role": "assistant", "content": "I will just give you the average of your two critiques as the grade for the 3rd critique."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When will the makeup final be for those of us who missed it because we were feeling sick and couldn't take the final this morning?"}, {"role": "assistant", "content": "See #1206."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I just realized in the spur of the moment I used the wrong device type to ask the TA if it was alright to use the bathroom during the test (asked him using my computer). Is this ok? I just wanted to make sure that it wouldn't effect my exam results."}, {"role": "assistant", "content": "This is fine!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I tried to join the zoom meeting for room 7 and it shows that \"This meeting ID is not valid. Please check and try again.\" Could someone verifies the meeting link?"}, {"role": "assistant", "content": "Please try this link: https://cornell.zoom.us/j/93871965793?pwd=OElQVnZRd3NMNG4wZ3p6d0RScW5WUT09"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello,\n\nMy name is Hali, I am supposed to be taking the final today but I am feeling very nauseated and congested (and overall gross) (and upset) (causally but also just in general). I have been feeling under the weather for a couple of days now which has made studying a little bit rough, but I was hoping that it would be better by the time I wake this morning\u2014it is not the case.\n\nI saw in the logistics post about requesting an SDS letter and taking a make-up exam; I have emailed SDS about it, too, but I am not sure how the process works for getting a letter for an instance of illness that is not a registered disability? \n\nSorry for any bother\u2026 hopefully all will be well within the next handful of days\n"}, {"role": "assistant", "content": "Professor Cardie said that it is ok to skip the final tomorrow and take a make-up exam at a later date. If we can\u2019t arrange that before grades are due she agreed to issue an Incomplete. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I am so sorry to say this is the last minute, but I do not think I can take the exam this morning. I was going to take it if I feel better after waking up, but although I took some medicines before I went to sleep last night, I am not still feeling well enough to take the exam. I am having a high fever and coughing a lot (which made me barely sleep last night) and I do not think I can solve problems properly on the exam. I just submitted the SDS form, so I will send it to Professor Cardie as soon as I get back from them."}, {"role": "assistant", "content": "Professor Cardie said that it is ok to skip the final tomorrow and take a make-up exam at a later date. If we can\u2019t arrange that before grades are due she agreed to issue an Incomplete. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Dear Professor/TAs,\n\nI've been feeling sick for the past two days and have been waiting for my supplemental test results. Tonight I experienced serious vomit, headache, cough, and a fever of 38.6 degrees celsius. I was waiting to see if the symptoms would reduce, unfortunately, they did not. I'm very mal-functioning and cannot fall asleep either.  I don't think I could recover by tomorrow morning, thus writing this post to attend the makeup exam, and already submitted a request for an SDS accommodation letter.\n\nThank you, and sorry for the last-minute situation.\n\nRaye\n\n"}, {"role": "assistant", "content": "Ok, sure. \n\nIt's fine to skip the final tomorrow and take a make-up exam at a later date. If we can\u2019t arrange that before grades are due I'll issue an INComplete."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I am living in the Lansing west and my internet somehow shut down. I am now using my hotspot and my internet still does not work. I noticed many of my neighbors face with same issues. I am stressed and really don\u2019t how to handle it.  I am really concerned about the reliability of my internet tomorrow. Where can I find a place with reliable internet?"}, {"role": "assistant", "content": "Spectrum had a (planned?) outage for maintenance.   It was supposed to be brief. But it wasn't.  It's back.   But \"brief\" outages could occur until 6am apparently.\n\nCould anything else possibly go wrong!!##$)@(#*@#)(@#"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "My internet just went out (I have tried everything to get it to come back on) and I am very concerned it won\u2019t work tomorrow. I am worried about being on campus because I am planning to leave the day after tomorrow and don\u2019t want to risk giving Covid to my fianc\u00e9es family in VA (I haven\u2019t seen anyone since the end of classes). \n\nWhat should I do if my connection isn\u2019t restored by tomorrow morning? I\u2019m kind of freaking out to be honest. I have almost no cell service in my apt so that isn\u2019t an option. I have two bars of lte at best, not enough for zoom. Should I call the number in the morning if my internet is not back on, or try to find a place on campus? "}, {"role": "assistant", "content": "should be back now.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I live alone and the building managers are planning to come into my apartment tomorrow at some point to inspect the smoke detector. Any suggestions on how to proceed if this happens during the exam? Am I allowed to speak to them (without getting up from my chair) to tell them what's going on so that they go about their business? Or should I do something more drastic like putting a DND sign on my door and ask them not to engage me if they come in?"}, {"role": "assistant", "content": "It\u2019s fine, just let the TA who\u2019s proctoring know about your situation. I\u2019d advice putting the DND sign so you don\u2019t waste time."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nI was wondering if final grades are curved, and if so, what would the curve look like? I talked with a TA who said they might be but I just wanted to confirm. Thank you!"}, {"role": "assistant", "content": "Overall grades in the class are usually not curved. However, they might be for each individual exam."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I just finished crying. It was actually the first time I cried in college. I don't cry in college I think, mostly because I know there's no one who is going to baby me and fix my problems here. I have friends I can rely on, but the way adults rely on each other, so I try to avoid crying because it doesn't really fix things. When I found out that I got what equated to a failing grade on my prelim 2 for MATH 1920 (28/100 - way below median) freshman first semester, I didn't cry and I sucked it up, instead performing well enough in the final (way above median) to pull my final grade up to a B.  I didn't cry during any of the other more personal hurdles I've had here either. I always told myself, there was something I could do, something I could fix or do better with, and if there was really nothing to be done then it wasn't worth beating myself up about. \n\nI think I'm pretty good with stress and I haven't ever said I'm going through a mental health crisis when actually it probably only affected me a little bit. I didn't complain or question when I heard we were moving online and not making anything open book or optional, because I really wasn't affected beyond being a little nervous at that time. I know this kind of stuff is serious and you cheapen it by bringing it up in every scenario. For example the bomb threat was scary (not normal where I'm from and I was in Upson), the shooter on north felt distant, and the fire alarm pulled in Regal Cinemas 2 minutes into the Eternals when I went to watch it 4 days after the shooter felt a little like a cosmic joke. I wasn't extremely affected though, and I never actively claimed stress with any of my profs.\n\nI just found out that I've been in close contact (came to my house yesterday, invited by my roommate who I've been in very close contact with) with someone who tested Positive Monday (she only found out today evening). My roommate has had a persistent cough since today afternoon, before we got news of this. To be honest if this were to happen in the middle of the semester I would be okay with it, however, this might mean I can't go home this year at all. All the flights to India are fully booked and if I miss my flight on the 19th morning, I definitely cannot go home for break. Considering the last time I went home was the last winter break, it would likely be a nearly 2 year gap by the time I see home again. I also need to renew my OCI (essentially a permanent visa) by December end for it to be valid in travel use, which I need to be in India to do. Otherwise, I'll be stuck relying on visas in this unreliable travel climate. They're also getting stricter with OCIs so what if they refuse to renew it after the deadline?  \n\nI'll be testing tomorrow morning but everything is so back logged that I'm honestly not sure what to do. I was going to get a ride with my roommate  and stay at overnight with her at NYC on the 18th, but that plan fell through because she has at risk parents and she's also been in close contact.  So now I have to take a bus to New York on the 17th or 18th, and I not sure if I'll have results by the time I take the bus. What if the bus journey gives me COVID? What if I am positive and I end up having to quarantine in an NYC hotel?  Not Ithaca home where I can expect friends to get me medicine and not India home where I would be looked after completely, but an unfamiliar hotel in an unfamiliar city. Should I be risking it at all? Should I just give up on home? What about by my family who I so rarely see? My OCI? I feel feverish, is that just placebo? I can't smell anything, I've had that problem forever, but is it COVID this time?\n\nI'm so incredibly stressed, and I don't know if I'll even be able to sleep. I'm the farthest thing from a good mental state to take the exam that it gets. I appreciate everything the course staff has done, and honestly I feel extremely embarrassed airing all this out, especially because I know people on course staff, but would there be any way to make up the final at a later time when things are less tense and frantic for me? I know there is no obligation to accommodate me but take this as me sincerely begging "}, {"role": "assistant", "content": "Divya, hi. You sound a bit of a mess at the moment :). I'm truly sorry for that!!!\n\nDefinitely ok to skip the final and take a make-up exam at a later date. If that can't happen by the time that grades are due, we'll give you an INComplete.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Where do we find our assigned zoom link?"}, {"role": "assistant", "content": "We will put it up soon "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I sent this message as an email to Professor Cardie and Magd a couple hours ago as well.\n\nI went home as soon as the NLP final was announced to be online as I didn't want to stay on campus and risk getting covid, but I believe I might have covid anyway. I feel extremely sick (I have a temperature of 102) and I also have a pain in my chest that is making it hard for me to breathe. I have tried to push through the sickness today and study but it has been really hard. Even during the mock exam session I was struggling to just keep focused and ignore the pain from breathing and my fever. I tried calling SDS but no one picked up so I left a message and emailed them (this was also 2 hours ago and I have not gotten a response from them). Is there any way I can take the final at a later date? I am even okay with getting an incomplete this semester and taking the final in person in January.\n\nThanks,\n\nAshok"}, {"role": "assistant", "content": "You can take a make-up exam at a later date.  If we can't arrange that before grades are due I will issue an INComplete.  "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "was the last minute review session recorded?\n\n"}, {"role": "assistant", "content": "Oh no :(\u2026I didn\u2019t record it because I did it so last minute and didn\u2019t remember to click the record button.\n\nI\u2019m sorry!!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "hi i'm really stressed out about the final and it's impacting my ability to study i don't really know what to do :')\n\ni guess im just worried because i didn't do enough over the weekend because i was so stressed out about the covid situation and now i feel like i'm not gonna be able to actually learn everything i need to for the final. and i've put SO many hours and so much effort into this class that if i do bad on the final since it's worth so much of my grade all that effort wont even matter:(\n\ni dont know if you can do anything to help but i figured i should probably reach out anyways \n\n"}, {"role": "assistant", "content": "Don\u2019t stress!! You\u2019re super active; Prof. Cardie and I both know you along with your situation. We also know that this time has really impacted a lot of people and so we know that things would\u2019ve been different under more normal circumstances.\n\nTake a break, take care of yourself then if you feel up to it then try studying a little bit to cover things you don\u2019t remember as well. You might surprise yourself on the exam tomorrow :).\n\nI\u2019ll still send this over to Prof. Cardie but I think you will still do well on the exam overall (and in the class)."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I accidentally missed the mock exam today. Is there anything I can do to make up for it?"}, {"role": "assistant", "content": "There's one more at 7pm tonight."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I live in a studio apartment with one more person. He's not in this class nor has he ever taken it. Is it okay if he's in the same room while I take the exam? I am still hesitant to go on campus to take it because of covid\n\n"}, {"role": "assistant", "content": "This is fine. During the room check, if asked about it then explain that it is a studio apartment (or whatever the situation is) and so there is not another place to take the exam with no one there"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "What do we do if we need to use the restroom during the exam? PM a proctor?"}, {"role": "assistant", "content": "You can go, we trust you. And please please don't take your phone to the bathroom, we don't want any unnecessary mishaps lol! "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Dear course staff,\nI have been sick for the last couple of days and have had a pretty bad headache since I woke up today, which has been affecting my reading and comprehension speed. I think I'll be okay to take the exam, but would I qualify for additional time given this?\n\nThank you,\nSahil\n\n"}, {"role": "assistant", "content": "If you feel you are not in good shape to take the final, you can take a make-up exam at a later date. If we can't arrange that before grades are due I will issue an INComplete. I can't authorize additonal time though."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I hope you all are doing well. I am reaching out regarding my concerns for the final exam and wanted to know if it was possible to make any accommodations. I can list down all the hindrances for me:\n\n1. I got my booster shot recently and have not been feeling well enough to prepare well for the exam. I could have gotten it after finals but I am an international student who has to fly back so that made it logistically complicated.\n\n2. I have an exam tonight and Friday which is making it difficult for me to set up everything for proctoring in between my study time. \n\n3. I do not come from a strong CS background. I started as a Business major at Cornell and picked up my second major in Information Science which is why I took this course. This may not be an excuse for accommodation but I wanted you to be aware of this well as the second half of the course (after midterm) was really difficult for me to catch up with. Also, I am on 22 credits this semester which made it even worse for me to manage my time. \n\nI talked to Sabhya about my situation as well. I really appreciate you going through my message."}, {"role": "assistant", "content": "You can take a make-up exam at a later date. If we can't arrange that before grades are due I will issue an INComplete. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I spent like an hour in office hours trying to learn all the derivative rules (I barely have any calc experience) but I still really don't understand how to apply them very well. How screwed am I/how much more time should I devote to this x(\n\n"}, {"role": "assistant", "content": "Don\u2019t spend too much time on derivative rules! We will generally give you derivative rules or they will one of the simpler +, * rules of derivatives.\n\nSPend your time elsewhere :)"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I was unable to find a way to request a regrade. My apologies if I simply failed to find the button."}, {"role": "assistant", "content": "regrades were available but I think they ended last week, I can open them again now "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is there a typo in this question since the third choice should be \"H2->Friend\"?"}, {"role": "assistant", "content": "yep, looks like a typo!  i can't believe that no one caught this until now, Robin :)."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is there a way to reset or overlay wandb plots from model to model? Eg, when I train my baseline model and then my mod_a model the plots just continue as below. I can't seem to find it in the wandb walkthroughs \n\n\n\n"}, {"role": "assistant", "content": "click that"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "This is regarding Critique 6. I could not find any statistics on the actual sentences in the training data anywhere and the data do not seem to be available for free to \"non-members\"."}, {"role": "assistant", "content": "Not sure myself, even the LDC site (https://catalog.ldc.upenn.edu/LDC2006T06)  for the dataset doesn't say much "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, we are getting an index out of range error in beam search after 500 iterations of first epoch. This error only came up after we used pretrained embedding (glove). \n\nI can't figure out what causes the error. Would really appreciate some help. Thank you! \n\nHere is the link to the notebook(editable): https://colab.research.google.com/drive/1u3979d2TE1IJZnQvoB4N1jTHLYLkgWML?usp=sharing\n\n"}, {"role": "assistant", "content": "TBH, if you get good enough scores without using pre trained embeddings just proceed with that at this point instead of spending time debugging this. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello,\n\nI hope you are doing well. I am writing to say that after being granted an extension until this Sunday (today) at 11:59pm, my group (shl98 and I, eo255) unfortunately submitted our PDF to gradescope a few minutes late. I want to say we are very grateful for this extension to help work around Sophie's medical needs, and we are not trying to take advantage of this whatsoever. We had ended up submitting our entire PDF to gradescope and ipynb notebook to CMS right on time, but when I went to assign pages, I noticed that part of the writeup that had been written in the ipynb directly were not on the PDF. I went and looked back and apparently there was a Latex conversion error when trying to download the PDF that caused the downloader to skip all those pages, and I did not know about it until literally assigning those pages. Immediately when realizing this, I went back and copy and pasted those answers into the google doc template and resubmitted. I am very very sorry for this, and I really hope it does not cost us a full half letter grade when the original timestamps show we were perfectly on time.\n\n\n\nThanks again,\n\nEric\n\n"}, {"role": "assistant", "content": "No worries! We won\u2019t mark this as late."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Dear 4740 staffs,\n\nI'm approved by SDS to receive homework extension when needed and I'm wondering if it's possible for me to be given an extension for P3 until December 3rd?\n\nBest,\n\nKeyi\n\n"}, {"role": "assistant", "content": "will tell @Claire about this "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In an older edstem post (#777) you said it would be easiest to look at LR vs RNN for this question, so would this answer not be sufficient/should I rework it to discuss LR?\n\n \n\n"}, {"role": "assistant", "content": "So parallelization and slowness would be a computational issue. Recall in #777 that we consider computational issues not to be a problem.\n\nAdditionally, the issue of using attention is still part of the RNN. So this is also not considered a valid issue as these should be issues with any RNN type architecture which includes those with attention.\n\nSo the hint of LR vs. RNN points to 1 major issue that can be used as an answer. This is meant more as a method to think about what differences exist and to help guide your thinking process. Think to P2 when you guys built LR vs. this model. What differences exist in these models in terms of advantages / disadvantages? Think about different use cases as well."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hey, I am getting error like this and we can't figure out why. We were wondering if anyone else got a similar error?"}, {"role": "assistant", "content": "Glad you were able to resolve this issue!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Does submitting Monday night count as 1 day late or 2 days late?"}, {"role": "assistant", "content": "This is 2 days. Sunday night is 1 day."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Just reposting my comment to #818 which didn't get answered. We have run our model for 15 epochs and seen the validation loss level out/start going up around epoch 8, but the bleu score continues to rise linearly. How do we know when to stop training our model? Theoretically I could train my model for 100 epochs, taking days of colab resources and I surely would get kicked off/throttled, but may end up with a better BLEU score. Do you have any suggestions on how to choose this hyperparemeter to balance the validation loss to BLEU tradeoff?\n\n"}, {"role": "assistant", "content": "When you stop is a design decision for you to make and justify / discuss. We discussed this in class so you should review your notes from the FFNN lectures.\n\n We offer a code section for you that performs a saving procedure for the best BLEU score. So what this means is we can run for a long number of epochs and we perform this early stopping procedure of saving the best BLEU score. You will need to still justify / discuss if you use our default method since you _choose_ to use this rather than another method.\n\nNow if you don\u2019t want to do this, then there are other options using validation loss for early stopping or based on the magnitude of the gradient update  (if it\u2019s a small update then we are probably near convergence and can stop!). There\u2019s doing it based on a number of epochs, and so on. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "The BLEU score the autograder gave our submission was around 29 but train_and_evaluate gave our model a BLEU score of around 32. Is this to be expected?"}, {"role": "assistant", "content": "This is expected. You are computing BLEU on a validation set while the autograder is on a test set."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In the following explanation, does the  W_v *h^{dec}_v refer to vocab_projection, \n\nand the W_{v_{target}} refer to output projection or vice versa? "}, {"role": "assistant", "content": "Vocab projection is $W_{V_{target}}$ while combined_output_projection is $W_{v}$"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Does a BLEU score of 1 mean that the model we made is written incorrectly or could it just require tuning the hyperparameters?"}, {"role": "assistant", "content": "I don\u2019t know where the post is on EdStem but BLEU is not an indicator of correctness or incorrectness. So it\u2019s possible to be correct with a BLEU of 0.005 or 45. Hard to say anything with a single number with no context. To check for correctness look at #729"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is there a way to retroactively enable my partner to join my cms group? Both of our names are on the submission but I forgot to add my partner, and it says that the submission would be lost in the merge when he requests to join. Or do I need to request the merge since I submitted the file?\n\nIf needed my netid is gh395 and his is yb233"}, {"role": "assistant", "content": "Don\u2019t worry about this, we will fix it if it is an issue."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "We submitted new model output just for the fun of it but we got this error on gradescope:\n\nThe autograder failed to execute correctly. Contact your course staff for help in debugging this issue. Make sure to include a link to this page so that they can help you most effectively.\n\nHere is the link. We are not sure what the problem is."}, {"role": "assistant", "content": "Rename your submission to submission.tsv"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Just wondering can we go back and try the leaderboard after the DDL? We have already submitted our work before the DDL. This should not make our entire submission late, right?"}, {"role": "assistant", "content": "Go for it! The leaderboard is open and you can keep making edits as you please with no impact on your grade. Submitting late or getting a certain score don\u2019t matter in this case. But you should still be submitting to the leaderboard!\n\nI want to see everyone\u2019s models climb up. It\u2019ll also be fun to hear what you all did for your models!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Will submitting in the next 30 minutes count towards a late penalty? "}, {"role": "assistant", "content": "Ahh. So I can\u2019t definitely say because there is no official grace period so technically it is late but we are generally lenient if it comes close to the deadline.\n\nPlease try to submit ASAP. It will probably be OK but I don\u2019t guarantee anything"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nCMS is showing submissions closed for p3 part 2. How do we submit our ipynb?"}, {"role": "assistant", "content": "You should be able to submit now!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nMy partner submitted our submission to CMS, but when I try downloading it it gave me this error: {\"status\":\"error\",\"errors\":[\"No file with type 3 and id 1031667\"]}. It seems to be working on her end, so just wanted to verify the submission is downloadable from the course staff's side. Thank you!\n\n\n\n\n\n"}, {"role": "assistant", "content": "I can download and open it. It looks like it has your code and everything so I think you are good to go! "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Ran out of time before I could fill out the miscellaneous section, would it be ok to submit it some other way? Don't want to make the P3 late on gradescope"}, {"role": "assistant", "content": "Go ahead and submit now on Gradescope . No late penalty :)."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Title"}, {"role": "assistant", "content": "You should clear all the output of your notebook then submit that. It should be smaller than 5000kb"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "^"}, {"role": "assistant", "content": "You should! We\u2019ll have the top models (including TA) discuss in class. Also it lets you see how well the models perform!!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Or is it okay if they're just in the writeup doc?"}, {"role": "assistant", "content": "Just the write up doc please!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I think the training procedure terminates when epoch reaches the limit, is there any specific point we should discuss in this question?"}, {"role": "assistant", "content": "Well it depends on if you use our training code or modified ours. If you use ours, We also have something else happen in the training procedure that saves the model which is the \u201cend\u201d of the training. What happens here? What is it doing and why does it make sense to do this?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I'm writing to ask if it would be possible to get a 48 hour extension on this project. I understand that the deadline has already been extended once, but I was unable to find a partner for this project as there's an odd number of students in the class, and I'm really struggling to finish it up. That being said, I have really enjoyed this project thus far and would like to submit my best work, so please let me know if an extension is possible. If not, I totally understand. Thanks for reading this, and have a good Thanksgiving break."}, {"role": "assistant", "content": "So although it seems there is an odd number, it should work out to an even number if we account for those auditing who don\u2019t partner with those who are graded.\n\nThat said, extension granted for 48 hours. It is now due on November 25 at 11:59 PM Eastern Time.\n\nCheers and enjoy your break!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I am currently working on automatically translating a list of sentences from modern English to Shakespearean, and looking into the source code for the live demo, there is a comment that says \"Bad Thing to Do Below.\" What exactly is this referencing? I have seen a few other posts of people getting nastyoutput from their models after running the live demo and I would like to avoid doing something bad.\n\nThank you!"}, {"role": "assistant", "content": "This refers to that line of code being bad practice. Nothing for you to worry about but just a warning when you build future systems to not use the globals() variable to access things."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In a previous post Prof. Cardie said that we should be able to change the glove embeddings without changing the embed size,  but upon trying to run it we get an error of \"input size: expected 300, got 50\". If we change this to 50 to make it compatible is that still considered one change in the ablation study (switching from glove 300 to glove 50)?"}, {"role": "assistant", "content": "We\u2019ll allow the change of embedding size if you use glove for both. However your baseline model would be 50 and ModA would be 300. The reason is that this modifications make the model more complex and you\u2019d ablate or remove this complexity as you go from ModA to Baseline."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi all,\n\nMy partner (Simar Kohli) and I are trying to wrap up P3, but he had to catch a bus and an exam today. While I also had to travel.\n\nI believe Simar sent an email asking for a one-day extension, to Professor Cardie yesterday but she hasn't responded yet. We were wondering if this was still possible?\n\nThank you!\n\nAngela Lau"}, {"role": "assistant", "content": "Hey,\n\nJust a reminder, ask any and all course related questions (including extensions!) on EdStem not email. We will miss any messages if they come via email.\n\nThat said, you have a 1 day extension until Wednesday Nov 24 @ 11:59 PM Eastern Time.\n\nCheers and enjoy your break!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "My partner and I divided the model work between the two of us. Is there anyway to import his runs into my wandb dashboard so that we have one cohesive table and graph? "}, {"role": "assistant", "content": "Not certain but this may be helpful? \n\nhttps://docs.wandb.ai/guides/track/public-api-guide"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Input sequence: \u201cI wore a jacket to the store today\u201d\n\nTranslation to Shakespeare: leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden leaden\n\nWe are wondering if this is a sign of a major error, or if it's just a sign that our model just doesn't do well? If it is the latter, do you have any advice on how to explain something like this? \n\n"}, {"role": "assistant", "content": "Please check #863 to see if this might be the issue! If not, then I can post more details. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When I was training my LSTM model with two layers and glove embeddings, my model reaches a 16 BLEU score very quickly but then quickly degrades down to very low BLEU scores even though validation loss and validation perplexity are steadily going down. I was wondering if this was a reasonable score and if these types of plots for the training are normal.\n\n"}, {"role": "assistant", "content": "Ok so I have limited information here on the model specifics. However based on what I do know, this does not entirely surprise me. This type of plot is entirely possible (about 50% odds from what I\u2019ve seen) with the configuration you\u2019ve described.\n\nJust a note: Loss and perplexity are correlated however BLEU is not necessarily correlated with them! There is a general trend usually that they are related but there is not a clear function mapping the two together. However PPL is just exp(loss) which is why they move together. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "We experimented with a few different configurations, but none of them perform better than our baseline model: in terms of bleu score, mod A and mod B perform similar to baseline, and applying both modifications lower our score. \n\nGiven similar bleu scores, it might be difficult to conduct a very good quantitative analysis or the theoretical reasons behind these performances. Should we try to find other configurations that can improve on the baseline? Or would it be enough to stick with them and conduct a qualitative analysis by observing examples and analyze how different models perform when translating? "}, {"role": "assistant", "content": "1) So it is perfectly acceptable to have modifications that don\u2019t impact performance too much. I agree that it makes it harder to do quantitative but there are still quantitative differences between the models as I don\u2019t think Model A and model B are going to get the exact same sequences translated correctly (maybe one does better longer sequences?).\n\n2) You can continue to suggest modifications and test them out or you can continue with the ones you have. We aren\u2019t grading you on scores but on the actual write up.\n\n3) Switching to qualitative is also perfectly fine! It\u2019s just a different type of nuanced analysis and everyone has their own preferences over which they like to do and think is easier. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "RuntimeError: Input and parameter tensors are not the same dtype, found input tensor with Double and parameter tensor with Float\n\nSo I am getting that the input and parameter tensors are not the same dtype when trying to do GloVe embeddings. How do I reconcile this? Should I condense the double embeddings to floats or expand the float parameters to doubles? Does it matter which I do?\n\nThanks!"}, {"role": "assistant", "content": "Call .float() on the embeddings tensor and try"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When we wanted to reload our model back to cuda and resume running it, we encountered a weird issue where the model loader is constantly using the default CPU to initialize and return the model.\n\n\n\n Just wondering if we can change the function so that the model device can be specified?"}, {"role": "assistant", "content": "You can change the function OR you can also perform a model.to(device) operation after loading the model that way it moves everything to the appropriate device. Both are valid methods."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is this because both of them are too high or have I messed up something in my implementation?\n\n\n\n\n\n"}, {"role": "assistant", "content": "Check your embeddings! You might have a NaN in them somewhere (I think you do based on the loss trend) value somewhere within the input which causes everything to become a NaN. NaN can also happen if your gradients \u201cexplode\u201d but we\u2019ve already handled / prevented that for you."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Since our group has no previous experience with RNN in NLP, so our strategy for stopping is simply to see via the w&b dashboard when the BLEU score starts to level out (or when computing an additional epoch is taking us too long). I am not sure if this can count as a justification of our stopping strategy. Are there any sources I can cite for this? Do we need to mention some possible early-stopping techniques even though we did not use any\uff1f\n\n"}, {"role": "assistant", "content": "This is mentioned in lecture as an early stopping technique. This can be used as justification for running a number of epochs and saving the best model. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\nDo we have to write about drawbacks of RNN specifically or do we have to right the drawback of Neural networks in general based on the fact that no feature engineering is performed?\n\n"}, {"role": "assistant", "content": "Well using a neural network does not mean we do no feature engineering. We\u2019ll see this next lecture but you can combine neural networks with feature engineering! This makes them quite powerful.\n\nSo the way to think about this question is why would we not want to use an RNN (assuming we have no computational constraints and we don\u2019t care about computational issues)? Why might we want a different type of model? What is a major drawback or concern that RNNs have that other models we have studied dont? (Hint: Think about LR vs. RNN for a task as this will be the simplest example to help you think about it.)\n\nAll the questions have been discussed in lecture so feel free to review your notes as well!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello! I think this code returns the correct enc_hidden and dec_init_hidden, but I'm finding it very difficult to test it through and through (my session keeps crashing).\n\nI tried to verify it with a sample of 5 sentences but then I get a little confused about the batch sizes (which is always 5 in the test run). \n\nSo just want to check if this looks okay or any indications of errors would be really helpful! \n\nThank you!  \n\n"}, {"role": "assistant", "content": "You need to specify dim=1 in torch.cat, the default is 0"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When can I expect model convergence w/o pretrained embeddings? I think another post said that you can typically expect BLEU/perplexity scores to bottom out after 2-3 epochs, but I am currently on my 5th epoch and BLEU score is still growing at ~11.5"}, {"role": "assistant", "content": "If your bleu scores keep growing, keep the model running. I'd say it should converge around 20 epochs."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is it okay if I make a private post to verify my implementation for the encoder? \n\n"}, {"role": "assistant", "content": "TLDR; You can make a post but it should be a post of just your code for us to verify. It needs to be more like OH where there is a back and forth.\n\nWe can help debug or walk through logic (and mapping code to logic) but we can\u2019t say \u201cYes this is 100% correct\u201d if that makes sense.\n\nThe easiest way to verify an implementation is to make sure all the sizes and types match our instructions. This ensures that most of the code will be correct and minor steps may be missed. You should do this then walk with a TA through the code to see what the steps align with what was told. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I'm running the model on smaller batches right now; the loss isn't converging and the bleu score goes down to 0. There's a user warning about 0 counts of 3-gram/2-gram sentences, so I was wondering what that means and if that could possibly be related to the model's current issues. \n\n"}, {"role": "assistant", "content": "1) This occurs because BLEU uses 1-4 grams to compute its score. If the generated translation doesn\u2019t have any higher order n-grams then this warning is raised. It\u2019s not of concern but just means the translations don\u2019t match the reference.\n\n2) What are the issues you are experiencing/ facing right now? BLEU is not a good way to debug or check your model."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! My partner and I were following along with Sabhya's advice to attempt to train our model on a small batch size and make sure that we had high bleu scores (>20). Unfortunately, after running for 20 epochs, we have a bleu score of just over 7 and our perplexity is about 19180, where we would expect our perplexity to decrease with time, not increase. It seems to us that this is indicative of a bug, but we were unclear about what exactly Sabhya was recommending that we try (should we be using the entire validation set for validating, or should we be evaluating on the same sentences we used for training?) so we wanted to double check that the results we are getting are in fact abnormal.\n\nThank you!\n\n"}, {"role": "assistant", "content": "So you misunderstood what Sabhya was saying. What you should be seeing is that the model can memorize the data which is in fact happening with the PPL for training being 1 and the loss approaching 0. This is expected.\n\nYou can\u2019t quite say what the validation would be but seeing it increase to be that large when your training is 2 data points is not surprising at all.\n\nTLDR; you misunderstood Sabhya and this is producing expected results with what you\u2019ve put in."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I am getting this issue when I try to run the model with my pretrained embeddings. Am I using the wrong data structure? \n\n"}, {"role": "assistant", "content": "Can you check earlier in that block of code that you didn\u2019t modify anything with the nn.Embedding that was initialized? It seems you modified that code block we gave you which is where the error is coming from."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "We are having a weird error where it's saying that out tensors are not all on the same device. By default, the tensors that we create in our encode and decode state should be on the same device as the entire model since they are functions within the model. I do not understand where we could have potentially placed our tensors onto the wrong device."}, {"role": "assistant", "content": "You definitely have an error here where you likely have what I call a \u201cdangling\u201d tensor. This is a tensor not attached as a parameter that you do not set the device for. You should check everything\u2019s device (even the things you think are parameters b/c you might think it\u2019s a parameter even though it is not). You can do this by printing the steps.\n\nAdditionally, you should **always** expand the error frames to actually see where the error occurred. The error message you placed above doesn\u2019t help because it\u2019s unclear where the error occurred. Based on the above, I have 2 guesses but it won\u2019t be known until you expand the error stack."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Just wondering how to find literature on these parameters? I have spent the entire afternoon trying to do so but could not find decent papers that include hyperparameters like these. Those parameters I found works even worse than the ones that come with the Notebook. Can we justify these hyperparameters by trying out some common values?\n\n"}, {"role": "assistant", "content": "Validated_every is not a hyperparameter. Hyperparameters are values like learning rate and batch size that can directly impact the training process. You justify those by finding other work and using similar hyperparameters (this makes it a more equivalent comparison). Additionally, there are common \u201cfolklore\u201d values that seem to do well (according to the general neural community) and you can additionally justify those by a similar logic.\n\nAnother common way is to experiment with a few different hyperparameters and choosing which one is best. All of these are valid ways to select hyperparameters and justify them for the write up."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In OH yesterday, I overheard Magd help someone debug some code by changing batch_size in the Decoder forward() function to be\n\nbatch_size = enc_hiddens.size(1)\n\n\ninstead of \n\nbatch_size = enc_hiddens.size(0)\n\n\nWhy is this/why would one want to change this ? I'm also trying to debug other stuff but everything leads me to new errors so I don't want to leave it as 1 in case it was specific to their issue. "}, {"role": "assistant", "content": "This is incorrect! You should not change this line.\u2019 To fix a dimension error associated with batch in the decoder forward you likely need to go back to your encoder and make sure that you have correctly modified / created enc_hiddens. There is a step where we reshape (using permute) and if you forget or do not do this step this will cause dimension errors.\n\nEven for the group yesterday, they do not have that line with a 1 but with a 0. It was mentioned as a solution but that requires lots of code modifications. It is much simpler to go back to the encoder and correct the size issue."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "How do we calculate V_t if we are using LSTM. Do we only apply combined output projection to the hidden state or do we also have to apply it to the cell state and combine them somehow?\n\nThanks!"}, {"role": "assistant", "content": "You can directly apply the combined output projection layer to dec_hidden!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, my partner and I have confirmed that the Tensor X that we make in our encoder has dimension (src_len, b, e). When we call pack_padded_sequence on X and use the source_lengths, we get an output with dimension (x, e), where x is some other integer that we don't recognize. We thought that we may have to modify source_lengths because X contains the embeddings of the source text, but when we used [i * self.embedding_size for i in source_lengths] as the lengths, we got an output from pack_padded_sequence of size (src_len * b, e). We run into an error where a function later on expects a 3d input but we give it a 2d one. We're not sure how to use pack_padded_sequence and maintain X as 3 dimensions, or if it should be 2 dimensions after pack_padded_sequence and there's something wrong later on in our code. Any help would be appreciated! \n\n"}, {"role": "assistant", "content": "I am not sure what is wrong with your implementation. But you don't need to modify source_lengths. You should get the same dimension after calling torch.nn.utils.rnn.pack_padded_sequence(X, source_lengths). You can check its documentation to see if you are using it correctly. \n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello,\n\nI hope you are having a nice day. I was wondering if I could receive clarification on the grading of Project 3 Part 1. My partner and I received points off for the \"Explained the error (why it is wrong)\" portion for two of the four questions. \n\nI looked carefully through the instructions for Project 3 Part 1 in both the written questions and the colab notebook and have attached them below: \n\n\"Please include a description of the error, a description of your fix, and a python comment in the code indicating where fix is for each of the 4 errors.\"\n\n\"Your objective is to find and fix each of these errors and to include in the report a description of the original error along with the fix.\"\n\nBased on the above directions, I believe our written responses do address the directions as stated in the assignment, and was wondering if it is possible to relook at our project. \n\nThank you!\n\nVivian\n\n"}, {"role": "assistant", "content": "Please submit a regrade on Gradescope. EdStem is not meant for regrades on projects. I am happy to clarify instructions but based on your post, I am unsure what the question or confusion regarding the instructions were."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "For the Nuanced quantitative analysis question, when you say: \"if model \ud835\udc4b achieves greater accuracy than model \ud835\udc4c , to what extent is \ud835\udc4b getting everything correct that \ud835\udc4c gets correct?\"\n\nWhat is meant by accuracy and how do we calculate the extent of it?"}, {"role": "assistant", "content": "Accuracy here refers to the metrics we use to evaluate the NMT task, BLEU. If you read the next sentence, you should get a better idea of what the questions is asking for: \"Alternatively, how is model performance affected if you measure performance on a specific strata/subset of the reviews?\" That's say if you are comparing RNN and Feedforward, you can compare their performance on different types of sentences, for example, sentences that has different lengths. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I tried submitting a regrade request a few minutes ago (still within a week after midterm answer key came out [11/12]), but it didn't go through, so I'll ask about it here:\n\nMy answer for intrinsic evaluation was marked off for not correctly defining w1-wn and N. However, I defined wi as the ith word in whatever document/sequence we're evaluating, and N as the number of tokens in the document we're evaluating. This seems to be exactly in line with the answer key except for the usage of document instead of corpus. I'm confused as to why/if this is incorrect, because we've seemingly used document and corpus interchangeably throughout class (such as when defining na\u00efve bayes). Is there a significant distinction between the two?"}, {"role": "assistant", "content": "Document and corpus are 2 different things. So this would be incorrect. A corpus is a collection of documents. A document would be a single item which could be a single sentence, a paragraph, or even an entire book.\n\nWe didn\u2019t use them interchangeably during class but we did interchangeably use sentence, sequence, paragraph, review, and document which is where the confusion likely came in."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "1. Apply the decoder to Ybar_t and dec_state to obtain the new dec_state\n\nTo clarify, are we meant to torch.cat Ybar_t and dec_state together and then apply self.decoder? "}, {"role": "assistant", "content": "No, Ybar_t is already the concatenation of Y_t and o_prev. Dec_state is the hidden state of the previous time step. If you are using RNNCell for your decoder, it takes inputs (input, hidden).\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi:\n\n1. It is correct that the \"embedding\" attribute is expected to be a nn.Embedding object (in both Encoder class and Decoder class) since Decoder class use self.embedding.weight.size(0) to retrieve the total number embeddings (i.e vocab size) in the decoder class? If not, is the \"embedding\" attribute expected to be a torch.tensor?\n\n2. Do we have to use the self.embedding initialized in Encoder in our forward method (\"forward\" method in Encoder class) to perform the transformation of word index to embedding? For example, I use customized pre-trained embedding (model) with gensim, and I can retrieve the word embedding vector of a word (input are indexes though) directly using built in functions of gensim to do the job, without using the self.embedding attribute initialized in the Encoder object. \n\n3. Is the target_padded tensor in the forward method of Decoder Class expected to be a tensor of int or a tensor of actual words (in tgt corpus)?"}, {"role": "assistant", "content": "1) The embedding attribute is expected to be an nn.Embedding object. This is handled for you automatically by the NMT class.\n\n2) You should use the self.embedding object. It will do the entire translation process for you. You can pass the embedding matrix that you create earlier in the code. If you did not do this (for whatever reason), then you should utilize the Vocab object to convert word -> index and the word -> embedding then you can place the appropriate word embedding into the proper index. If you do not do this, there will be lots of code modifications\n\n3) target_padded is a LongTensor (2D; [SeqLen, Batch]) that where every value in this tensor represents the index of the embedding to fetch. You won\u2019t need to handle passing the values to forward because we do this for you."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "How much should we look at the Live Running Demo to determine the performance of our model? Should we be concerned if the output of our NMT does not seem to be coherent? \n\nFor example: we have a multi-layer LSTM with no embeddings and the input sentence \"why should i play the roman fool and die on my own sword?\" outputs \"why what one that that that that that that that and in a upon of upon i then to how and, on? ,, ?, ?? ,, ,, ,, ,, ,? ,, ?, ,, ,? ,, ?, ,, ,, ,, ,, ,, ,, ,,,\". \n\nWe tried the single-layer LSTM, and LSTMs with word2Vec and glove embeddings, and they all seem pretty erroneous. \"cheer ingenious ingenious ingenious ingenious ingenious cape rogues appals screen snow snow snow snow snow snow snow snow may may stories monster admirable admirable bodies palpable besort besort cockatrice diest diest tips bill calves shake usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp usurp\" was another example. \n\n"}, {"role": "assistant", "content": "So the Live Running Demo is especially useful if you want to pass in validation sentences or your own especially if you are doing the qualitative analysis for Section 3 (within model analysis). How coherent your model sounds will likely be highly correlated with the BLEU score (< 10 is incoherent, < 20 is somewhat coherent but may be hard to get the gist, < 30 much clearer translations with some grammatical errors, and so on).\n\nSince we are not grading on the performance of your model, it is possible to get a perfect (or really high) score without having a very coherent translation model. However, it is easier to do analysis if the model produces something that is not nonsense either. You can play with the hyperparameters of the beam search (width and max length) because it seems the second one is too long and makes no sense. You can shorten the max length to something closer to the input length."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, \n\nIn the call dec_state=self.decoder(Ybar_t,dec_state) (in decoder step method)\nWe are getting the following error  \n\n/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py in forward(self, input, hx) \n    input, hx, \n    self.weight_ih, \n    self.weight_hh,\n-> self.bias_ih, self.bias_hh, \n )\nRuntimeError: input has inconsistent input_size: got 640 expected 128\n\n\n\nThe size of Ybar_t after concatenation  is (16,640)\nWe are not able to figure out why the expected size is 128 at the internal function call pasted above."}, {"role": "assistant", "content": "If it expects 128, it means that the self.embed_size that the decoder cell was initialized with is 128. Read through your entire code and track the embed_size and make sure you pass in the correct one!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! For the embeddings section, we tried both training our own embeddings (skip gram), and just directly using the text as source and target. And the models using padded text performs better than the one taking skip gram embeddings as input.\n\nIs embedding necessary for the baseline model? Because if we try to choose the baseline according to performance, we would submit the one without any embeddings.\n\nAlso, we feel like embeddings should improve the performance of our model. We did the embeddings as the following:\n\nWe created our Word2Vec models separately for source and target, each trained on the tokenized source and target texts. And we build the embedding matrix as the following:\n\nif word type is in Word2Vec model, directly use the vector trained\n\nif word type is not present and is one of <padding>, sentence beginning/end, then we use the zero vector\n\nFor tokens likes <unk>, we choose to use the mean among all vectors.\n\nSorry for the lengthy post. We are just really confused by our embedding's performance!"}, {"role": "assistant", "content": "Using embeddings is not compulsory. You can get a full score on the project even if you use None for embeddings."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Our group is using LSTM for the module, and we're currently stuck on calculating the dec_init_state. I noticed that while in the comment it says that `last_hidden` is a tensor shape (2, b, h), the (h_n, c_n) output we get from applying the encoder is of dimension (D\u2217num_layers,N,Hout\u200b), (D\u2217num_layers,N,Hout\u200b), so I'm really confused on how to use them to get the dec_init_state. I'm also confused on how to apply the h_projection layer.\n\nThe code for our current implementation is as followed:\n\n\n\nAlso, I would like to have a clarification on the meaning of h_n and c_n. Is h_n = ht, and c_n = Ct in the graph below?\n\n\n\n"}, {"role": "assistant", "content": "The documentation here is written with an RNN an mind not an LSTM however it is a simple extension. We assume the number of layers is 1 (and  it\u2019s a trivial extension to num_layers > 1). In this case, we expect a (2, b, h) tensor for the hidden and a (2, b, h) tensor for the cell state. We need to modify these tensors concat the forward (index 0) and backward (index 1) directions giving us a (b, 2 * h) tensor for the hidden and another ones for the cell state.\n\nAfter we finish this, we can now apply an h_projection and c_projection just like we apply any other linear layer or the embedding layer or encoder layer. \n\nAnother thing is that **all** of our dimensions list batch as being the 2nd dimension. You should not be setting batch_first=True if the batch dimension is not first!! Please read through the instructions (the math and the TODO code blocks) to make sure you understand the dimensions and flow of what\u2019s happening. Additionally, please read the PyTorch documentation that is linked."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I'm stuck on one part for the encoder:\n\nAfter I pack X, when I try to call the encoder, I get this error: \nRuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\n\nAnd I'm not sure how to resolve it: I pass in the source_padded, source_lengths to the encoder, is that not what is expected? \n\n\n\n"}, {"role": "assistant", "content": "You\u2019re supposed to encode the source padded first to get X using self.embedding. You then pass in X into the self.encoder."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Someone left a bracelet in Gates after office hours today! It\u2019s on the table by the door where it was left"}, {"role": "assistant", "content": "thanks for posting about this Anna!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi guys,\n\nSo my project partner recently dropped the course, and I figured there are others in the same boat as me. Does anyone need a new project partner for the upcoming projects? Let me know! You can message me here, or email me at my netID, amg369. Thanks!"}, {"role": "assistant", "content": "I'll make a new thread for this soon! "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I might be wrong but I remember lecture notes submission closes right before next lecture? I'm used to revisit my notes on weekends and then submit."}, {"role": "assistant", "content": "So usually we have a 2 day (or 48 hour) window for submission. That\u2019s the guaranteed window, but we sometimes will extend it on the Thursday one a little longer until Sunday or Monday. However this is an informal extension and not a formal thing that one requests an extension for etc."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "No rush or anything, and it's of course fine if not, but will critique 2 grades be released before critique 3 is due? I didn't do too hot on critique 1 and seeing if my critique 2 is more on track to meet expectations would help me on critique 3, I feel.\n\nThank you!"}, {"role": "assistant", "content": "If you would like feedback on critique 1 / advice for the next one you can schedule a meeting with me sometime tomorrow? (email me @ssc255)\n\nCritique 2 grades are almost done, only ~10% left. We'll release them as soon as they're done!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I'd like to request a regrade for Quiz 2, question 3 since my answer looks correct, just with another combination of choices for parentheses/brackets usage, quotation marks, and the spelling of POS tags.\n\n"}, {"role": "assistant", "content": "will check"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nThis was to highlight that I have mentioned my comments(copied below) on quiz 2 and quiz 3 requesting a regrade of the questions, would request you to please consider the same. Following are the comments:\n\nQuiz 2:\n\nThe answer to the Q3 has been marked incorrect while the answer is correct. I have mentioned NN(Noun) instead of NN, would request you to please review.\n\nQuiz 3:\n\nQ4 has been incorrectly marked. The probability is calculated as follows:0.003*0.087*0.00068=0.00000017748 I have mentioned the correct answer in the box, request you to please re-check."}, {"role": "assistant", "content": "will take a look later "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "(1) CS 4740 / CS 5740 \u2013 Discussion (edstem.org)\n\nHi, I had a quick question about our regrade for P1. I put the post above that details the exact issue, but I added a comment a few days ago and wanted to make sure you guys saw it. Thank you, and sorry for the extra post\n\n"}, {"role": "assistant", "content": "resolved on gscope "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Can I get a regrade for problem 3 on quiz 2? I believe my answer is correct."}, {"role": "assistant", "content": "yes will take a look tomorrow!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "^\n\n"}, {"role": "assistant", "content": "doing"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I was wondering if I can get quiz 2 regraded?\n\nI think the answer was right, just not in the format for Canvas to recognize. Thank you!\n\n"}, {"role": "assistant", "content": "sure, i'll take a look"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "  Hi, my project partner just chose to take audit for this course\u2019s grading base, which means he will no longer work on any project. \n  Should I find another partner or join a current group? Otherwise, maybe I can work solo from now on?"}, {"role": "assistant", "content": "You will need to find a new partner for P3 / P4. When we release, we will make an announcement for partner finding as well where you should post regarding a partner."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Just wanted to make sure someone saw #315, since I haven't gotten any confirmation yet.\n\nBut in general, what would be the best way to get ask for a quiz regrade? Would a private post be likely to be addressed more quickly than a public one? Or a new post instead of a comment?"}, {"role": "assistant", "content": "You can make a private post and I'll handle the regrade"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! We were wondering if Professor Cardie\u2019s office hours were still happening today from 9:30-10:30 am? Thanks!"}, {"role": "assistant", "content": "They should be. Is Professor Cardie not in her office?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nIn class, it was mentioned how U functions as a normalizer to ensure output values are between 0 & 1. However, I see that h, its self is the output of a sigmoid function that would limit the range between 0 to 1. Why then would we require an additional function U to constrain the values further ? May I know if I am missing something in my understanding ? \n\n"}, {"role": "assistant", "content": "U is a weight matrix similar to W. It does NOT normalize the values between 0 and 1 that is the purpose of sigmoid / softmax in the final layer for classification (ie. $\\sigma(z)$). U is simply taking the output of the previous layer and applying some transformation to it before we apply the \u201csquashing\u201d via softmax / sigmoid."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "KC and I are seriously running out of steam tonight and were wanting to take an extra day and just deal with the -5 points, but we saw that gradescope and kaggle close tonight. Since we got an extension are we not allowed to use late days? Or can the deadline be extended on kaggle/gradescope?\n\nThank you!!\n\n"}, {"role": "assistant", "content": "Resolving!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "<3"}, {"role": "assistant", "content": "We wish <3"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nI want to reach out to Professor Cardie to see if it is still possible for me to pass the class. I'm having doubts and was wondering if I could schedule a meeting with her. Thank you!"}, {"role": "assistant", "content": "Brian, hi.  Can you let me know some times you're free on Monday?   I will also look at your scores so far over the weekend."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When will project 3 be released?"}, {"role": "assistant", "content": "We are shifting P3 to early next week (Monday / Tuesday) so that you all get a break. We felt it was a lot in a short time for you all and you all deserved a break :). We may adjust P3 time frame as needed"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Any ideas? ;-;\n\n-Anna & KC"}, {"role": "assistant", "content": "Are you using log probabilities for everything? If you use log probabilities, do you make sure that the initial max value is -inf?\n\nWhat features are you using for your model? What are you replacing in Viterbi (transition, emission, both, None)? Did you try replacing the transition and keeping the emission?\n\n@Sabhya, are you free to help more in-depth?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Are the median and the upward shift of the curve that were announced for the midterm also applicable to the make-up exam? Or are the make-up exam stats different?\n\n"}, {"role": "assistant", "content": "So the curve and stats included all of the exams (make up, regular, and extended time). I can see if anything major is different between them in terms of curve or stats however I believe that will not be the case."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! We are having some issues using the prob function from nltk in our MEMM viterbi algorithm. We are getting this error, but the only arguments prob should need is (self, sample). Any idea what the issue could be? We've been debugging viterbi for a while so there could be a deeper issue that we're not seeing. \n\nHere's the documentation we were looking at:\n\nhttps://www.nltk.org/api/nltk.probability.html#nltk.probability.ProbDistI\n\nhttps://www.nltk.org/api/nltk.classify.maxent.html#nltk.classify.maxent.MaxentClassifier.prob_classify\n\nHere is the rest of our code for this function (we haven't polished it sorry that it's kinda messy)\n\nOn a different note, we were planning on going to every office hour today and our morale kinda took a hit since they were all cancelled (very understandably!!!). We were wondering how late you all were planning on being active on edstem since our project is due tonight? We're a bit worried about hitting a major hurdle after everyone is asleep!\n\nAs we've written this post we also realize we're still a bit conceptually confused about what the probability we're getting in memm_calc represents and how that relates to figuring out the NER tags. If anyone has a couple of minutes to spare I think we would really benefit from a short call to talk it through, but we totally understand if you're all busy!!!\n\nAnyways, thank you for all that you do!!! And thank you all so much for all the help you have given us for this project!! We really appreciate you guys so so much!!"}, {"role": "assistant", "content": "Resolved!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "the expectation of the exam was quite different from the actual exam\n\nthe expectation was to finish in 1 hour and similar to the quizzes and practice exam.\n\n1.5 hours feels like a more accurate expectation. I also thought the professor said the exam will be shorter than the practice, but I might have misheard that. I paced myself too slowly in the beginning, expecting extra 30 minutes, and panic answer toward the end.\n\nsetting expectations to quizzes, practice exams, and also topics not covered by quiz and practice might be more accurate. I expected more computation and short answers and expected POS/NER instead of opinion and thematic role.\n\n"}, {"role": "assistant", "content": "Hi, I'm really sorry that you feel this way. Our hope for the course is to be as open and accommodating. We want all the students to do well and there was never any intention to \"trick\" y'all in the midterm. Thank you for bringing these points up to our attention. I would like to address them (not rebut them).\n\n1. It wasn't mentioned that the exam will take just one hour. After sifting through a few past prelims I can confirm they have all been of similar length. Even if we had said the exam should take 1 hour instead of 1.5 hours I don't think this should have changed the way that you prepared for the exam. Moreover, on the day of the exam, it was mentioned that we expect that most of you will take the entire 1.5 hours going into the exam.\n\n2. We recognize the material that was on the exam may have been slightly unexpected from the POV of the students, however, it was material that was all covered in depth in the lectures. Nothing that wasn't covered in depth in the lectures appeared on the exam. Moreover, everything you needed to know to answer the opinion extraction, chunking, and semantic role labeling questions was present on the slides. In fact, on the day of the exam, during the review session on Tuesday, @Magd went deep into the concepts of chunking and worked through a real example. More on this, questions 1, 2, and 4 were exactly like the material we had seen in the quizzes, projects, and practice. In fact, during the review session on Sunday, @Aliva prepared extra material on this and I even answered two questions (from q4) that showed up on the actual exam. \n\nNonetheless, we recognized that the students may have found certain parts of the exam rather challenging, especially if they focused more on studying the models rather than the NLP tasks. I believe (and the other TAs would agree) that we were fairly lenient in our assessment of these questions and we tried to give the students as many points as possible. Beyond being lenient while grading, we even mentioned in #509 that we will be curving all the grades up (tentatively by 7 points). So that's 7 free points for everyone.\n\nAnother thing to keep in mind is that the exam is just worth 10% of your grade, which is lesser than all of the projects. So please don't be disheartened by the grade you received. There are still lots of opportunities to do well in the course!\n\nIf there's anything else, please feel free to let me know, I'd be happy to discuss it with you. We appreciate your feedback!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I know regrade requests are not being accepted until the solutions are posted but based on the guide given on gradescope I believe the provided solution for thematic role labelling is partially incorrect, or at least ambiguous. Should I wait until regrade requests are open? Or should I go ahead outline what I think the issue is with the given solutions on gradescope since this might affect multiple people? Thank you!!"}, {"role": "assistant", "content": "These were examples of what I expected students to answer (and what I wanted us to accept).   They aren't the solution.   Getting the correct solution would be too hard for students who have not studied this in a linguistics class.  \n\nSo I don't think it's worth it to outline the problems at this point."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "On Question 5.2 the comment for my answer was \"LOCK\". I am not sure what is meant by that\n\nThanks\n\n"}, {"role": "assistant", "content": "Don't worry about it. It's just something for us that helps avoid conflicts while grading. We are getting rid of it now. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi\n\nOur P2 is due tomorrow and we are on MEMM. We have been trying to figure out what to do for like 3 hours, but I think we need considerable help. We are really confused about how to structure our feature sets & what to put into the MaxEnt classifier, the structure of the input, etc.\n\nI know you're all grading right now since we ran into Professor Cardie in Gates, but is there any possibility someone could point us in the right direction before office hours tomorrow? We were hoping to get some good work done on MEMM tonight and we're just feeling a bit lost.\n\n(We're on the second floor in 222 if a guardian angel would like to help us. We'll probably be here for... a while.)\n\nThanks so much and happy grading :)\n\nAnna & KC"}, {"role": "assistant", "content": "Are y'all still here?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nJust wanted to get some clarity around an issue I faced while performing project 2. Though I managed to finish the project around the deadline, I must say it was really hard doing so; my teammate left the course in between and his contribution towards the project turned out to be minimalistic. I think what particularly made this situation harder was the fact that it came out unannounced, driving me to make several changes to my schedule just ahead of my midterms. I think there was a noticeable cascading effect to my exams as well since my time was severely contained in light of this. \n\nAt the moment, I do not have a teammate and I'm in search of one but more importantly, I really want to avoid this situation in the future. Could you help share your thoughts on this?\n\n\n\n"}, {"role": "assistant", "content": "Hi Jayaram. I'm really sorry to hear this. CS 4740 is a project heavy course and like several other CS classes requires students to pair up for the assignments. Although students dropping the class is something completely out of our control, we do try our best to support students in situations like yours. My advice would be that before partnering up with a student you have a clear conversation with them about their intents of staying in the class, the amount of time they will be putting in, and their general schedule. Further, if you do find yourself in such a situation again where you have a bunch of other commitments lined up, please come speak to one of the TAs / Prof. Cardie or post on Ed and we will try our best to provide you with certain accommodations. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! I have a final project in my morphology class where we can write a paper, do research, and present on whatever we want in morphology and I was curious if I would be able to incorporate some NLP topics. I was told to post here and Professor Cardie might know of some papers I could look at to get ideas. Thanks! :)\n\n"}, {"role": "assistant", "content": "I would go to the ACL Anthology: https://aclanthology.org/\n\nAnd type in \"morphology\" into the search bar (upper rhs).   Or type in something more specific if there's something of particular interest to you.\n\nAfter doing this, a few of the papers that looked interesting to me at least were these (although I don't normally read the morphology papers):\n\nhttps://aclanthology.org/2020.acl-main.596.pdf\n\nhttps://aclanthology.org/P19-1156.pdf\n\n\nhttps://aclanthology.org/2021.eacl-main.162.pdf"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello, I just found out that the midterm was tonight on Tuesday and not Thursday. Due to some personal issues, I have been having a hard time keeping up with classes and somehow totally missed the edStem post. I'm not sure why I was under this impression, even though I went to class today and didn't happen to hear at all that the midterm was tonight. I don't want to drop the class - is there a way I can make up the midterm?\n\n"}, {"role": "assistant", "content": "Hi, that is okay don't worry about it. Hope you're taking care of your health. Would you be able to give it tomorrow? One of us can proctor it for you?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In this formula for Naive Bayes, which statement is the prior and which is the likelihood estimate?"}, {"role": "assistant", "content": "P(c_j) is the prior and P(x_i |c_j) is the likelihood estimate"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In the skip-gram training: Is \"input \u00b7 output\" the dot product of their semantic embedding vectors? Or something else?\n\n"}, {"role": "assistant", "content": "This is the dot product between the two vectors (input from Embedding matrix and output from Context Matrix)"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Are we expected to know all of the theta roles/syntactic categories for the exam? Or would they be given to us? Like some sort of list?"}, {"role": "assistant", "content": "No, you don't need to memorize all syntactic categories. For this exam at least. I would focus on more conceptual topics rather than memorizing all this info."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello, I think the denominators should be switched between the precision and recall equation definitions in the project 2 embedded equations. Precision = |TP|/ |TP + FP| and recall = |TP| / |TP + FN|.\n\nTP + FP = |P|\n\nTP + FN = |T|"}, {"role": "assistant", "content": "Thanks for pointing it out. I agree with what you said, denominators should be switched between the precision and recall in the description. In the code part, it is correct. "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "For my implementation of HMM when computing the HMM scores for an input sentence, as the words later in the sentence are processed, the scores becomes extremely small. Is this supposed to happen? For very long input sentences, I am getting a score of zero for everything near the end of the sentence. In this case when taking the maximum score when all the scores are 0 should we choose the Named Entity label to be 'O' as default? Also in case of a tied score which label should we choose?\n\n"}, {"role": "assistant", "content": "Are you using log probabilities? If you aren't then you should. Can you try changing your implementation to use log probabilities? If you are already doing this there's probably a big mistake in the code or a flaw in your understanding, in which case I'd need to see the code to know more."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "what is the hmm_build function supposed to return/what exactly is a 'representation' of an hmm? \n\n"}, {"role": "assistant", "content": "That is up to you to decide. You don't have to use that function. We just thought it would be nice if you had one variable referring to your entire hmm model instead of keeping track of its different components and calling those components every time you want to use them. \n\n\nSo for instance, if you call build_transition, build_emission, and build_start_state_probs in your build_hmm function you could store all 3 of those results in one compact representation so that you can refer to an \"HMM\" model easily in the future without having to pass many parameters / call many functions! \n\nIf you show me your code during OH I can advise you on how to change it so that it follows this style of coding. While it isn't compulsory, it will make your life much easier! \n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is it fine if I do Project 2 on my own or do I absolutely have to form a group? \n\n"}, {"role": "assistant", "content": "Please try to find a group but if you can\u2019t and just wanna get started then you can do it by yourself "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi all:\n\n    Does anyone know what framework of pos-tagging is used in our training corpus (e.g. Penn Treebank Tagset)? This is important since it will affect the smoothing solution for pos-tagging in the test stage of our trained models. :-) "}, {"role": "assistant", "content": "You absolutely don't need to do POS tagging in this assignment. Your HMM only needs to predict NER tags, NOT POS tags. So you don't need to store any information related to POS tags in the transition and emission matrices. The reason why we have given you the POS tags is so that you can use them in your feature engineering stage in the MEMM model. If there is anymore confusion please get it clarified before doing your implementation."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Are office hours still happening today at 11? Thanks!\n\n"}, {"role": "assistant", "content": "Yes! There was an issue with my device but you can rejoin now!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "How should we be indexing / identifying each which word corresponds with which index in our emission matrix?"}, {"role": "assistant", "content": "Could you explain your question in greater detail? I'm not quite sure I fully understand the issue."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello! Is it possible for a word that is in the training data multiple times to have more than one type of NER tag associated with it?\n\nFor instance: the word \"June\" could be a PER or an O?  How would we handle this case?"}, {"role": "assistant", "content": "Yes, in a preprocessing step you can loop through the entire dataset and count the number of times a given word w_i is tagged t_i.\n\nOops, I think someone deleted the comment?"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I have a time conflict for the Midterm on Oct. 19th. Is there any form I need to fill out now? Thank you!\n\n"}, {"role": "assistant", "content": "Please email prof Cardie. She\u2019ll let you know what to do!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is smoothing necessary for the transition matrix? \n\nIf so, if I were to use laplace or add-k smoothing, would the size of my vocabulary V be the number of NER tags in the training set (<5 if I were to work with a subset), or should it be the total number of NER tags (for this project, 5)? I am referring to the bigram formula below.\n\nThank you!"}, {"role": "assistant", "content": "Yes, you should be using add-k smoothing for your transition matrix. As for the vocab size V, let me check with the other TAs and confirm and get back to you!\n\nEdit: V should be 5 (ORG, PER, LOC, MISC, and O)"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "The kaggle submission expects an \"Expected\" column, but the create submission function instead uses a \"Predictions\" column name. Therefore we aren't able to submit to kaggle unless modifying the create_submission function. Can someone change the kaggle submission format requirement?\n\n"}, {"role": "assistant", "content": "For some reason, I'm not being able to change it on Kaggle. Kaggle wants it to be \"Expected\". Are you able to submit if you change it to \"Expected\". If yes, then you can modify the create_submission function on your end and we can modify it on the release notebook too!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Are we allowed to skip some critiques as long as we submit 3 by the end of the semester? or do we have to complete all in order to have only the top 3 count?\n\n"}, {"role": "assistant", "content": "You need to submit at least 3. So you can skip 3 and then the 3 that you submit will count.\n\n(This is only valid for cs 4740 students, if you are enrolled in cs 5740 then you must submit all 6)"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hey,\n\nI was expecting a response from Professor Cardie regarding my extension #196. Please let me know the decision made. \n\nBest,\n\nAhmad\n\n"}, {"role": "assistant", "content": "No extension has been given. It seems you are enrolled in 4740 (Undergraduate) so we will be taking the best 3 out of 6 (if this is incorrect then please let me know). This is a perfect opportunity to drop one of the critiques since you feel it may be too much for you."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When we are building probability matrices in Part 2, are we using just tokens and NER labels or do we also have to use POS tags? "}, {"role": "assistant", "content": "We are using just tokens and NER labels. The POS tags are given so that you can use them for feature engineering in your MEMM model. They are of no use in the HMM."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In the lecture notes, we define start states and end states to be \"a special start state and end (final) state that are not associated with observations, together with transition probabilities a_01a_02...a_0n out of the start state and a_1Fa_2F ... a_nF into the end state\"  \n\nI'm a little confused by this definition. Would it be appropriate to think of a start state as the probability of a certain label occurring \"first\"? So for the project, would we find the probability that each label is the \"first\" in a sentence? a document? \n\nThanks in advance!\n\n"}, {"role": "assistant", "content": "Yes, for eg. the start state for the tag PER will be the probability of the tag PER occurring in the first word of the document. The data we released to you is in the form of documents and your Viterbi algorithm will also be reading in documents (multiple sentences). Hence, you must calculate the start state probs by going through all the documents and looking at their first words and the tags they have.\n\nAnd yes what you said --> \"Would it be appropriate to think of a start state as the probability of a certain label occurring \"first\"?\" --> is correct! "}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello,\n\nIf I reference other published literature or modeling methods within my critique, does citing those sources count against the 1 page limit or can a works cited page be submitted on a second page. Thanks."}, {"role": "assistant", "content": "Citings can be on the next page! Don't worry."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, we are implementing calculation of emission matrix, and we are not sure how emission probabilities are defined in this problem.\n\nLet  t_i be the NER tag for word w_i, and pos_i be the corresponding part of speech of that word. \n\nShould emission probability be P(w_i|t_i), or should we combine word and POS as the emission from NER tags, i.e. P(w_i, pos_i|t_i)? \n\nWe think pos is important to help predict NER tags, but we are confused about where to use it. \n\nThank you!"}, {"role": "assistant", "content": "The POS tags are given so that you can incorporate them with your features when building the MEMM. You don't need to consider POS tags AT ALL when building the HMM. Hence, the emission probability must be: P(w_i|t_i) where t_i corresponds to the NER tag."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Can I assume there's no smoothing for question 2?\n\nI was under the assumption that the question will be explicit whether to smooth or not, the question didn't specify so I assume there's no smoothing\n\nIf there should assume smoothing, can I resubmit the question? 4/327680\n\n"}, {"role": "assistant", "content": "I graded this under both assumptions."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I found a couple of things on this quiz confusing.\n\nQuestion 2: It's unclear if we're supposed to use smoothing or not. It doesn't say to, but the example shown in class used smoothing.\n\nQuestion 3: I can't seem to identify 4 binary co-occurrence features, only really 2, or max 3. Also, the expected formatting is unclear - should we put quotes around word tokens?\n\nI already submitted my quiz, but I think it might help other students to make the questions/expectations more clear.\n\nThanks!\n\n"}, {"role": "assistant", "content": "Thanks for the comments, Sahil!!!  (I meant to thank you earlier, but have been swamped :).  )  \n\nDefinitely continue with the quiz comments!  (I've marked you down for class participation credits for this.)\n\nclaire"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "For the sample given to us for the HMM in Project 2, 'Cornell', 'University', 'is', 'located', 'in', 'Ithaca', 'and', 'was', 'founded', 'by', 'Ezra', 'Cornell'. \n\nIsn't this a really bad sample to test our HMM on, since none of the non 'O' tokens (like Cornell and Ezra) are actually in the training corpus at all, and therefore the HMM has no way of knowing their emission probabilities? \n\nOur HMM does not recognize most of the non 'O' words correctly, and we think this is why. \n\n"}, {"role": "assistant", "content": "A couple of things:\n\nThere is a section for handling unknown words, in which you must prepare your models to handle unknown words such as Cornell and Ezra.\n\nThe sample observation was just given so that you have something immediate to test your model with. There was no intention of checking the scores/values that your model produces based on the sample sentence. You can test it with whatever you like."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Can we use NLTK's bigram and other functions in Project 2?"}, {"role": "assistant", "content": "Yes, the use of the NLTK bigram function is allowed for P2.\n\nAnd yes, NumPy is allowed as well!\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "For the HMM matrices, for example the transition_matrix in Section 2, each entry represents the probability of moving from one state to another, but are these states NERs or are they POS? Because if they are POS, which ones should we be sure to concern ourselves with?"}, {"role": "assistant", "content": "We are doing NER in Project 2. So for all of P2, we will be using HMMs for NER and the states should be one of the 5 tags given to you $\\{O, PER, LOC, ORG, MISC\\}$."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nI am studying for the quiz and believe I found an error on the \"In Class Exercise\" slide where we predict the class of a document using NB modeling. I think the equation \"P(\u201cand\u201d|Positive)=(1+1)/(5+12)\" should actually be P(\u201cand\u201d|Positive)=(0+1)/(5+12), as the word token \"and\" is not observed in any of the positive documents. The resulting calculation on the following slide would need to be updated as well.\n\n"}, {"role": "assistant", "content": "Thanks for catching this!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Questions:\n\n1. For the NB probability calculation, are we assuming add-1 smoothing? In the lecture notes two forms are given, the latter of which uses add-1 smoothing which I assume is what is expected here but wanted to double check.\n\n2. Are we counting punctuation as a separate word token? And if that punctuation is a comma should we escape it somehow in the feature vector to distinguish between the commas used to separate features?\n\n3. For the binary co-occurrence features, are we assuming our window size contains the whole sentence? And should we use true/false or 0,1 in the feature vector?\n\n4. For the POS, is writing it out fully like \"verb\" or \"noun\" fine or should we use one of the encodings provided in the lectures?\n\n"}, {"role": "assistant", "content": "Thanks, Scott, for pointing out the things that were underspecified in quiz 2.  Points totally taken.   I've tried to make the allowable answers accommodate all reasonable assumptions.   Rest assured, for a real test, I'd be more specific."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "It looks like there's nowhere to submit critique 2 yet.\n\n"}, {"role": "assistant", "content": "I\u2019ll make it right now, give me 15"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi,\n\nMy partner just dropped this class. I think all students should have their partners by now. Can I do P2 on my own or can I form a group of three? "}, {"role": "assistant", "content": "I think there are other students looking for new partners. I can make a thread to help y'all connect."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Not sure if I am the only one but I tried accessing the link for critique paper 2 in the resources page on edstem from multiple devices and browsers and I could not get it to load. Any guidance or help would be appreciated, thanks! :)"}, {"role": "assistant", "content": "Hi, I have fixed the link now.\n\nTry: https://homes.cs.washington.edu/~nasmith/papers/bamman+smith.icwsm15.pdf\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I am a little unsure on the difference between token-level and entity-level NER class distribution that is mentioned in Q1. Is it possible to get some clarification on this? Thank you!"}, {"role": "assistant", "content": "Please look at #205"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "What should we do if we have a prelim conflict on October 19th?\n\n"}, {"role": "assistant", "content": "Please email Prof. Cardie. I will let her know too."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "When my partner and I were computing the emssion probabilities, we noticed that there were slight discrepancies in capitalization with certain words like Miama vs. MIAMI.  Setting all the words to lower case would fix this problem when finding the probability of a word given a tag, but should we preprocess the data?"}, {"role": "assistant", "content": "IMPORTANT EDIT: If you are doing preprocessing then please make sure you don't change the indices of the data. Especially the test data. You can achieve better than the baseline without preprocessing. However, if you wish to make everything lowercase, that is allowed.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is Professor Cardie still having office hours from 11am-12pm today, in Gates 417? I've knocked several times, but I can't tell if anyone is there.\n\n"}, {"role": "assistant", "content": "Sorry for the late reply! Prof. Cardie had something come up and wasn\u2019t able to make it. We forgot to make a post and update the calendar.\n\nApologies about that!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello,\n\nI have two questions regarding the project.\n\n1. Is my group allowed to use the spacy tokenizer and associated functionality in that Python package?\n\n2. Is my group allowed to use/adapt small code snippets that I have personally written in the past. For instance, I may want to adapt a code snippet I wrote that tunes a scikit pipeline with optuna + custom scikit learn transformers.\n\nPlease let me know. Thanks!"}, {"role": "assistant", "content": "Apologies for the long response!\n\n1) Using a different tokenizer is perfectly OK as long as you know what it does. Q1.2 in your write up asks about your preprocessing so you would mention the use of X tokenizer there as well. In terms of \u201cassociated functionality\u201d this is quite vague of a question. Some functionality might be allowed but I also don\u2019t think almost any of it would be useful for this project. You must build the N-Gram model **from scratch** so I am not sure what you would get out of the spacy package. Feel free to follow up below or in office hours.\n\n2) When you say \u201ctransformers\u201d here I assume you are referring to a feature transformation rather than the model architecture known as transformer (We will learn this later!). As long as the N-Gram model is being built from scratch (not using a prebuilt model or code from anywhere), you clearly mention the code reuse in your report and code (where is this code, how is it used, how much has been reused), and it is a small snippet (e.g. 5 lines of your entire project has been reused from other project) then this is acceptable."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Is perplexity defined on a per review basis, or for the full test corpus? In other words, is N the number of words in one review, or the number of words in the full test corpus, consisting of k reviews? \n\n"}, {"role": "assistant", "content": "Perplexity can be computed on a corpus level as well as a review (document) level. Making the decision of what to compute depends on why you are computing the perplexity. One would make sense in certain situations where the other may not."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi all,\n\nI hope you're doing well. I wanted to make a post because I just got my quiz 1 score and I was marked wrong for question number 2. However, when I checked the quiz solution that was posted, it states the answer is 9/246. I put 3/82 as my answer, which is the reduced form of 9/246 so I was wondering if there was an error in grading. \n\nThanks for the help!\n\n"}, {"role": "assistant", "content": "Could you recheck the grade? It should be correct"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi! I was wondering if there are any restrictions on what packages/libraries we are or aren't allowed to use for the project? Thank you! \n\n"}, {"role": "assistant", "content": "While there isn't a fixed list of packages that aren't allowed, please make sure that you implement the models from scratch. Hence, packages such as nltk.ngrams is not allowed.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I just saw that quiz 1 has been regraded. My grade becomes 0/100 and last week when I submitted it shows 100/100. I was wondering if this is normal (i.e. all my quiz answers are actually wrong) ? "}, {"role": "assistant", "content": "So everyone\u2019s quiz was regraded to include variations (simplifying or including/excluding unigram probability) but no score has gone down from the submission time. Scores have only increased with the regrades.\n\nYou should be able to see correct / incorrect on the quiz for each of the questions. The solutions are also posted on EdStem"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, \n\nApologies for reaching out for such a minor thing. \n\nI believe that that Question 2 on my Quiz 1 may have been incorrectly graded. \n\nI got a probability of 9/18. I calculated this probability by only using bigrams, which seems to be acceptable as per post #42 on Edstem. Accordingly, I am not sure whether I am making some mistake here or this was incorrectly graded. I also heard that 1/2,  which is equivalent to 9/18, was accepted for other students,\n\nThanks,"}, {"role": "assistant", "content": "This has been resolved."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, \n\n\nFor Q2 on Quiz 1, I got a final probability using bigram model as 3/82 and verified with a TA during lecture that the approach taken to get the answer is correct. Hope the grade for the same could be fixed.\n\n"}, {"role": "assistant", "content": "This has been resolved."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi professors and TAs,\n\nI have been so busy preparing for two interviews and one written exams for Fall recruitment this weekend and begin a little late to write the critiques.\n\n I have finished it several minutes later than the due time (I finished writing at 12.08 pm) and the  submission window is closed.\n\nThe critique is attached below.\n\nI wonder if it is possible that you can open the window for a short period so I can submit this.\n\nThank you so much!\n\n"}, {"role": "assistant", "content": "Thanks, Lihe, I will check with the rest of the course staff as to what the late policy is and let you know accordingly!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello!\n\nI've just recovered from a bought of COVID scare and a cold so I'm a bit behind on all of my work. I couldn't make it to office hours to ask, so I was hoping someone would be able to help me out on EdStem. \n\nI'm not sure as to what the columns on page 313 on the critiques refer to? They're labeled P,R, and F. \n\nThank you!"}, {"role": "assistant", "content": "They refer to Precision, Recall, and F1 scores. These metrics are used to evaluate model performance. This link might be useful for a gentle introduction to these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "We are working on Unsmoothed Bi-gram Model (Part 2.2).\n\nI know that we are not allowed to use existing tools for counts and computing probabilities, but are we allowed to use ngrams() to obtain bigrams from the text? Or do we have to write a loop to obtain bigrams.\n\nThanks!"}, {"role": "assistant", "content": "No, you are not allowed to use ngrams() from NLTK or any such package. \n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I have been having some cold/covid-like symptoms for a couple of days now and have isolated myself to stop the spread (and to follow Cornell's guidelines). Is it possible to join the class over zoom instead while I am remote? Thank you so much!\n\n"}, {"role": "assistant", "content": "Unfortunately, we will not be holding zoom sessions or recording lectures this semester. I would suggest going through the lecture slides, textbook and coming to OH to catch up if needed! Hope you feel better!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "The instructions ask us to keep in mind about two things:\n\nperiods at the end\n\napostrophes\n\nHowever, the sample tokenizer given to us already seems to treat periods and apostrophe-ed affixes as separate tokens for us, which is a good thing, so I am confused as to what else I am expected to do from here --- it seems as if all of the preprocessing has already been done for us."}, {"role": "assistant", "content": "There isn't one correct method of preprocessing in NLP. Decisions regarding preprocessing depend on the ML/NLP practitioner who must decide what preprocessing may be suitable for the problem at hand. From an assignment POV, you don't need to have more preprocessing if you don't want to. You do however need to answer any questions related to preprocessing. \n\nBut to motivate the reasoning for other kinds of preprocessing, consider the following sentences-\n\n\"I walk to class every day.\" \n\n\"He walks to class every day.\"\n\nThe word walk will be counted differently in these sentences. But when using N-gram models do we want them to be treated differently? Certain preprocessing might help deal with this. \n\nAgain, what preprocessing is to be used is completely up to you. Hope this helps!\n\n\n\n\n\n\n\n\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "As title. \n\n"}, {"role": "assistant", "content": "Projects must be done in groups of 2. If you have trouble finding a partner, we can assist you. If you have extenuating circumstances, please come talk to us or elaborate on EdStem and we will take it into consideration."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "I can't find anything on cmsx. \n\n"}, {"role": "assistant", "content": "You can find the data on Kaggle as well."}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hello! \n\nI've been late on campus due to visa issues. Now, when I finally made it to NYC and decided to check the auditorium, it turned out that the course is taught in Ithaca. I'm a Cornell Tech student and based on Roosevelt Island. This situation happened because we have an NLP course here as well (but during spring). I enjoy the class and am very reluctant to drop it. May I please ask you to provide Zoom links for me? So that I can attend remotely...\n\n\n\n"}, {"role": "assistant", "content": "Hi Anastasiia!\n\nUnfortunately, We don\u2019t have a remote option this semester for this course. NLP is taught by Prof. Yoav Artzi at Cornell Tech in the spring. I can check with Prof. Cardie if something like this is possible but I would guess not.\n\nI\u2019m sorry that this happened!"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Right now, we have defined perplexity for a test W = w1 w2 ... w_n. However, currently, for any n-gram model (say unsmoothed unigram), we have a set of k reviews, and a real review ngram and a fake review ngram. \n\nHow do we combine all of this information into a single perplexity score, in order to be able to directly compare language models? \n\nWould this be a reasonable approach: \n\nfor each n-gram model type (fake review, real review): \n\n   compute the perplexity for each review \n\n   compute mean of perplexities \n\nAverage results combined above to get a single perplexity. \n\n\n\n\n\n\n"}, {"role": "assistant", "content": "The instruction said \"Compute and report the perplexity of each of the language models (one trained on true reviews and fake reviews)\" so there's no need to combine them. A model is good if it has low perplexity for both true and fake reviews.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "In the description of Part 2, it asks us to add a symbol to mark the beginning of a sentence. I am looking at the Sept. 2 lecture, and p.25-28 seem to be describing unseen n-grams. Is the note describing <s>, which we should include at the beginning of every sentence? \n\n"}, {"role": "assistant", "content": "I think the page number is probably incorrect. You can refer to Sep 2 slides p5-8. Yes, the convention of padding the beginning of sentences is <s>.\n\n"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "Hi, I'm trying to add my partner in Gradescope and I can't find the place to do so, does anybody know? Or do you add the partner when you submit? Thanks!"}, {"role": "assistant", "content": "You add a partner after a submission! It will give you the option to create a group after you submit"}]}
{"messages": [{"role": "system", "content": "You are an university teaching assistant chatbot that guides students"}, {"role": "user", "content": "On Kaggle, is the score we get from prediction just the accuracy of our model? Also, what score is considered high from this bigram model we are implementing?"}, {"role": "assistant", "content": "Yes, the score you see is the accuracy. Getting a high score depends on your implementation and how you are making the predictions. Therefore, focus on correctness in implementation and your model will do well. We have provided a baseline on Kaggle. You should expect your model to at least beat that score."}]}